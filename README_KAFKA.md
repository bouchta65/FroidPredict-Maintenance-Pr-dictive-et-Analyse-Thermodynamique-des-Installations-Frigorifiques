# FroidPredict - Maintenance Pr√©dictive et Analyse Thermodynamique des Installations Frigorifiques

FroidPredict est une application web innovante d√©di√©e √† la maintenance pr√©dictive des installations frigorifiques industrielles, alliant analyse thermodynamique avanc√©e et visualisation en temps r√©el des donn√©es de capteurs avec int√©gration Kafka pour le streaming de donn√©es.

## üöÄ Fonctionnalit√©s principales

- **Streaming de donn√©es en temps r√©el** avec Apache Kafka
- **Surveillance en temps r√©el** des √©quipements frigorifiques (compresseurs, condenseurs, √©vaporateurs, etc.)
- **G√©n√©ration de donn√©es factices** pour tests et d√©monstrations
- **Collecte et stockage** des donn√©es capteurs dans PostgreSQL via une API Python/Flask s√©curis√©e
- **Analyse thermodynamique avanc√©e** : calculs automatiques des points de cycle, COP, titres de vapeur, d√©tection des phases, etc.
- **D√©tection d'anomalies** et pr√©diction de pannes gr√¢ce au Machine Learning
- **Alertes et notifications** en cas de d√©rive des param√®tres critiques ou de risque de panne
- **Dashboard React interactif** : visualisation temps r√©el (diagrammes de Mollier, courbes de performance, historiques‚Ä¶)
- **Gestion des utilisateurs** et authentification s√©curis√©e
- **Interface Kafka UI** pour monitoring des topics et messages

## üõ†Ô∏è Stack technique

- **Backend** : Python, Flask, SQLAlchemy, PostgreSQL
- **Streaming** : Apache Kafka, Zookeeper, Kafka UI
- **Frontend** : React, Chart.js/Plotly.js
- **Data Science/ML** : scikit-learn, pandas, numpy
- **D√©ploiement** : Docker, Docker Compose
- **G√©n√©ration de donn√©es** : Faker, scripts de simulation

## üìä Architecture Kafka

### Topics Kafka
- **sensor_data** : Donn√©es des capteurs en temps r√©el
- **alerts** : Alertes et notifications
- **maintenance** : Demandes de maintenance

### Producteurs
- G√©n√©rateur de donn√©es factices
- API endpoints pour envoi de donn√©es
- Syst√®me de d√©tection d'anomalies

### Consommateurs
- Processeur de donn√©es pour stockage en base
- Analyseur thermodynamique
- Syst√®me d'alertes

## üéØ Objectif

Permettre aux industriels de :

- Pr√©dire les d√©faillances avant qu'elles ne surviennent
- Optimiser la performance √©nerg√©tique des installations
- R√©duire les co√ªts de maintenance et les pertes op√©rationnelles
- Visualiser et comprendre le comportement thermodynamique de leurs machines
- Analyser les donn√©es en temps r√©el avec Kafka streaming

## üì¶ Installation et Configuration

### Pr√©requis
- Python 3.11+
- Docker et Docker Compose
- Git

### 1. Cloner le d√©p√¥t
```bash
git clone <repository-url>
cd FroidPredict-Maintenance-Predictive-et-Analyse-Thermodynamique-des-Installations-Frigorifiques
```

### 2. Configurer l'environnement Python
```bash
# Cr√©er un environnement virtuel
python -m venv .venv

# Activer l'environnement virtuel
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate

# Installer les d√©pendances
pip install -r requirements.txt
```

### 3. Configurer les variables d'environnement
Copiez le fichier `.env` et modifiez les valeurs selon votre configuration

### 4. D√©marrer les services avec Docker
```bash
# D√©marrer Kafka, Zookeeper, PostgreSQL et Kafka UI
docker-compose up -d

# Ou utiliser le script batch sur Windows
start_kafka.bat
```

### 5. D√©marrer l'application
```bash
# D√©marrer l'API Flask
python app.py

# Ou utiliser le script batch sur Windows
run.bat
```

## üîß Utilisation

### D√©marrage rapide

1. **D√©marrer les services** :
   ```bash
   # Windows
   start_kafka.bat
   
   # Linux/Mac
   docker-compose up -d
   ```

2. **D√©marrer l'API** :
   ```bash
   # Windows
   run.bat
   
   # Linux/Mac
   python app.py
   ```

3. **G√©n√©rer des donn√©es factices** :
   ```bash
   # Windows
   generate_data.bat
   
   # Linux/Mac
   python generate_fake_data.py --mode batch --equipment 5 --batches 10
   ```

### Interfaces web disponibles

- **API FroidPredict** : http://localhost:5000
- **Kafka UI** : http://localhost:8080
- **PostgreSQL** : localhost:5432

### Endpoints API principaux

#### Kafka Integration
- `GET /api/kafka/health` - V√©rifier l'√©tat de Kafka
- `GET /api/kafka/config` - Configuration Kafka
- `POST /api/kafka/send/sensor` - Envoyer des donn√©es de capteur
- `POST /api/kafka/send/alert` - Envoyer une alerte
- `POST /api/kafka/generate/batch` - G√©n√©rer des donn√©es par lot
- `POST /api/kafka/generate/start` - D√©marrer la g√©n√©ration continue
- `POST /api/kafka/generate/stop` - Arr√™ter la g√©n√©ration

#### Equipment Management
- `GET /api/equipment` - Liste des √©quipements
- `POST /api/equipment` - Cr√©er un √©quipement
- `PUT /api/equipment/{id}` - Modifier un √©quipement
- `DELETE /api/equipment/{id}` - Supprimer un √©quipement

#### Sensor Data
- `GET /api/sensors` - Donn√©es des capteurs
- `POST /api/sensors` - Ajouter des donn√©es de capteur
- `POST /api/sensors/bulk` - Ajouter des donn√©es en lot
- `GET /api/sensors/statistics/{equipment_id}` - Statistiques

## üìä G√©n√©ration de donn√©es factices

### Via l'API
```bash
# G√©n√©rer des donn√©es par lot
curl -X POST http://localhost:5000/api/kafka/generate/batch \
  -H "Content-Type: application/json" \
  -d '{"num_equipment": 5, "num_batches": 10}'

# D√©marrer la g√©n√©ration continue
curl -X POST http://localhost:5000/api/kafka/generate/start \
  -H "Content-Type: application/json" \
  -d '{"num_equipment": 5, "interval_seconds": 10}'
```

### Via les scripts
```bash
# G√©n√©ration par lot
python generate_fake_data.py --mode batch --equipment 5 --batches 10

# G√©n√©ration continue
python generate_fake_data.py --mode continuous --equipment 5 --interval 10

# Avec un taux d'anomalie √©lev√©
python generate_fake_data.py --mode batch --equipment 5 --batches 10 --anomaly-chance 0.3
```

## üîß Configuration Kafka

### Topics cr√©√©s automatiquement
- `sensor_data` : Donn√©es des capteurs (3 partitions)
- `alerts` : Alertes du syst√®me (3 partitions)  
- `maintenance` : Demandes de maintenance (3 partitions)

### Monitoring avec Kafka UI
Acc√©dez √† http://localhost:8080 pour :
- Visualiser les topics et messages
- Surveiller les producteurs/consommateurs
- Analyser les performances
- G√©rer les configurations

## üöÄ D√©ploiement

### D√©veloppement
```bash
# D√©marrer tous les services
docker-compose up -d

# D√©marrer l'API en mode d√©veloppement
python app.py
```

### Production
```bash
# D√©marrer avec Docker Compose
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

## üìà Monitoring et Logs

### Logs de l'application
Les logs sont configur√©s avec le module `logging` de Python et affichent :
- Donn√©es re√ßues et trait√©es
- Alertes g√©n√©r√©es
- Erreurs et exceptions
- Sant√© des services Kafka

### Monitoring Kafka
- **Kafka UI** : Interface web pour monitoring
- **Logs des conteneurs** : `docker-compose logs kafka`
- **M√©triques JMX** : Port 9997 pour int√©gration avec des outils de monitoring

## ü§ù Contribution

1. Fork le projet
2. Cr√©er une branche pour votre fonctionnalit√©
3. Commit vos changements
4. Push vers la branche
5. Cr√©er une Pull Request

## üìù Exemples d'utilisation

### Envoyer des donn√©es de capteur
```python
import requests

data = {
    "equipment_id": 1,
    "sensor_type": "temperature",
    "sensor_location": "compressor_inlet",
    "value": 25.5,
    "unit": "¬∞C"
}

response = requests.post("http://localhost:5000/api/kafka/send/sensor", json=data)
print(response.json())
```

### Cr√©er une alerte
```python
import requests

alert = {
    "equipment_id": 1,
    "alert_type": "thermal_anomaly",
    "severity": "high",
    "title": "Temp√©rature √©lev√©e d√©tect√©e",
    "description": "La temp√©rature du compresseur d√©passe les seuils normaux"
}

response = requests.post("http://localhost:5000/api/kafka/send/alert", json=alert)
print(response.json())
```

## üîç D√©pannage

### Probl√®mes courants

1. **Kafka ne se connecte pas** :
   - V√©rifiez que Docker est d√©marr√©
   - Attendez que Zookeeper soit compl√®tement d√©marr√© avant Kafka
   - V√©rifiez les ports 9092 et 2181

2. **Erreurs de base de donn√©es** :
   - V√©rifiez la configuration PostgreSQL
   - Assurez-vous que les tables sont cr√©√©es

3. **Erreurs Python** :
   - V√©rifiez l'environnement virtuel
   - Installez les d√©pendances : `pip install -r requirements.txt`

### Commandes utiles

```bash
# V√©rifier l'√©tat des services
docker-compose ps

# Voir les logs
docker-compose logs -f kafka

# Red√©marrer un service
docker-compose restart kafka

# Nettoyer et red√©marrer
docker-compose down
docker-compose up -d
```

---

*FroidPredict : l'intelligence thermodynamique et le streaming de donn√©es au service de la fiabilit√© industrielle !*
